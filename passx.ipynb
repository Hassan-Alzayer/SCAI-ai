{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (4.7.0.72)\n",
      "Requirement already satisfied: numpy in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.26.4)\n",
      "Requirement already satisfied: roboflow in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.0.5)\n",
      "Requirement already satisfied: pafy in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.5.5)\n",
      "Requirement already satisfied: youtube_dl in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2021.12.17)\n",
      "Requirement already satisfied: certifi==2022.12.7 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (1.4.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (3.8.2)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (10.1.0)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (1.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (2.2.0)\n",
      "Requirement already satisfied: wget in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (3.2)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (4.66.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (6.0.1)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->roboflow) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->roboflow) (4.46.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->roboflow) (3.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sulta\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy roboflow pafy youtube_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Select input mode:\n",
      "1) Local Image\n",
      "2) YouTube Video\n",
      "3) Camera\n",
      "4) Local Video\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# ====================================\n",
    "# 1. MODEL SETUP VIA ROBOFLOW\n",
    "# ====================================\n",
    "rf = Roboflow(api_key=\"JEQebQNC9eADoMrYVTfR\")  # Replace with your Roboflow API key\n",
    "workspace = rf.workspace()\n",
    "\n",
    "# Load your project model – now using \"crowd-density-ou3ne\" version 1.\n",
    "project_crowd = workspace.project(\"crowd-density-ou3ne\")  # Ensure this matches your project slug.\n",
    "model_crowd = project_crowd.version(1).model\n",
    "\n",
    "# Choose this model for inference.\n",
    "model = model_crowd\n",
    "\n",
    "# ====================================\n",
    "# 2. INFERENCE PARAMETERS & SPEED OPTIMIZATION\n",
    "# ====================================\n",
    "# These parameters can be modified later.\n",
    "confidence_threshold = 1   # For example, 1% confidence (modify as needed)\n",
    "overlap_threshold = 50     # For example, 50% overlap threshold\n",
    "label_display = False      # Set to False to not display labels on bounding boxes\n",
    "\n",
    "# Resize factor for processing frames (e.g., 0.5 means process at half resolution)\n",
    "resize_factor = 0.5  # Adjust this factor to speed up inference (values between 0 and 1)\n",
    "# Frame skip: process every 'frame_skip'-th frame (1 = all frames, 2 = every other frame, etc.)\n",
    "frame_skip = 1       \n",
    "\n",
    "# ====================================\n",
    "# 3. SELECT INPUT MODE (Image, YouTube Video, Local Video, or Camera)\n",
    "# ====================================\n",
    "print(\"Select input mode:\")\n",
    "print(\"1) Local Image\")\n",
    "print(\"2) YouTube Video\")\n",
    "print(\"3) Camera\")\n",
    "print(\"4) Local Video\")\n",
    "mode = input(\"Enter 1, 2, 3 or 4: \")\n",
    "\n",
    "input_mode = \"\"\n",
    "if mode == \"1\":\n",
    "    input_mode = \"image\"\n",
    "    image_path = input(\"Enter the path to your image file: \")\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Image not found.\")\n",
    "        exit(1)\n",
    "elif mode == \"2\":\n",
    "    input_mode = \"video\"\n",
    "    import pafy\n",
    "    video_url = input(\"Enter the YouTube video URL: \")\n",
    "    video = pafy.new(video_url)\n",
    "    best = video.getbest(preftype=\"mp4\")\n",
    "    cap = cv2.VideoCapture(best.url)\n",
    "elif mode == \"3\":\n",
    "    input_mode = \"video\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "elif mode == \"4\":\n",
    "    input_mode = \"video\"\n",
    "    video_path = input(\"Enter the path to your local video file (.mov supported): \")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "else:\n",
    "    print(\"Invalid mode selected.\")\n",
    "    exit(1)\n",
    "\n",
    "# ====================================\n",
    "# 4. SETUP REGIONS (ZONES) COVERING THE FULL IMAGE AREA\n",
    "# ====================================\n",
    "# Determine frame dimensions from a static image or from the first video frame.\n",
    "if input_mode == \"image\":\n",
    "    orig_height, orig_width = image.shape[:2]\n",
    "else:\n",
    "    ret, first_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Cannot read video stream.\")\n",
    "        exit(1)\n",
    "    orig_height, orig_width = first_frame.shape[:2]\n",
    "    # rewind the stream if needed\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "# Apply resizing for processing: all processing will be done on this scaled frame.\n",
    "proc_width = int(orig_width * resize_factor)\n",
    "proc_height = int(orig_height * resize_factor)\n",
    "\n",
    "# Define the full image area (processed resolution) as four rectangular zones (2×2 grid).\n",
    "zones = {\n",
    "    \"Zone 1\": {\n",
    "        \"points\": [(0, 0), (proc_width // 2, 0), (proc_width // 2, proc_height // 2), (0, proc_height // 2)],\n",
    "        \"color\": (255, 0, 0)  # Blue in BGR\n",
    "    },\n",
    "    \"Zone 2\": {\n",
    "        \"points\": [(proc_width // 2, 0), (proc_width, 0), (proc_width, proc_height // 2), (proc_width // 2, proc_height // 2)],\n",
    "        \"color\": (0, 255, 0)  # Green\n",
    "    },\n",
    "    \"Zone 3\": {\n",
    "        \"points\": [(0, proc_height // 2), (proc_width // 2, proc_height // 2), (proc_width // 2, proc_height), (0, proc_height)],\n",
    "        \"color\": (0, 0, 255)  # Red\n",
    "    },\n",
    "    \"Zone 4\": {\n",
    "        \"points\": [(proc_width // 2, proc_height // 2), (proc_width, proc_height // 2), (proc_width, proc_height), (proc_width // 2, proc_height)],\n",
    "        \"color\": (0, 255, 255)  # Yellow\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert each zone's point list into a NumPy array (polygon).\n",
    "for zname, zdata in zones.items():\n",
    "    pts = np.array(zdata[\"points\"], dtype=np.int32)\n",
    "    zones[zname][\"polygon\"] = pts\n",
    "\n",
    "def point_in_polygon(point, polygon):\n",
    "    \"\"\"Return True if the point lies inside or on the boundary of the polygon.\"\"\"\n",
    "    return cv2.pointPolygonTest(polygon, point, False) >= 0\n",
    "\n",
    "# ====================================\n",
    "# 5. DEFINE A FUNCTION TO PROCESS A FRAME\n",
    "# ====================================\n",
    "def process_frame(frame):\n",
    "    # Resize frame for faster inference.\n",
    "    proc_frame = cv2.resize(frame, (proc_width, proc_height))\n",
    "    \n",
    "    # Run inference using the Roboflow model on the resized frame.\n",
    "    # (Assumes model.predict() accepts a frame directly.)\n",
    "    result = model.predict(proc_frame, confidence=confidence_threshold, overlap=overlap_threshold).json()\n",
    "    detections = result.get(\"predictions\", [])\n",
    "    \n",
    "    # Convert center-based predictions to bounding boxes.\n",
    "    # (Coordinates are relative to proc_frame, so no scaling needed.)\n",
    "    person_bboxes = []\n",
    "    for det in detections:\n",
    "        x_center = det[\"x\"]\n",
    "        y_center = det[\"y\"]\n",
    "        box_width = det[\"width\"]\n",
    "        box_height = det[\"height\"]\n",
    "        x1 = int(x_center - box_width / 2)\n",
    "        y1 = int(y_center - box_height / 2)\n",
    "        x2 = int(x_center + box_width / 2)\n",
    "        y2 = int(y_center + box_height / 2)\n",
    "        label = det.get(\"class\", \"Person\")\n",
    "        person_bboxes.append([x1, y1, x2, y2, label])\n",
    "    \n",
    "    # Assign detections to zones.\n",
    "    zone_counts = {zname: 0 for zname in zones.keys()}\n",
    "    annotated_bboxes = []\n",
    "    for bbox in person_bboxes:\n",
    "        x1, y1, x2, y2, label = bbox\n",
    "        rep_pt = (int((x1 + x2) / 2), y2)  # bottom-center of bounding box in proc_frame coordinates\n",
    "        matched_zone = None\n",
    "        for zname, zdata in zones.items():\n",
    "            if point_in_polygon(rep_pt, zdata[\"polygon\"]):\n",
    "                matched_zone = zname\n",
    "                zone_counts[zname] += 1\n",
    "                break\n",
    "        annotated_bboxes.append({\n",
    "            \"bbox\": bbox[:4],\n",
    "            \"zone\": matched_zone,\n",
    "            \"label\": label\n",
    "        })\n",
    "    \n",
    "    # For visualization, work on the processed (resized) frame.\n",
    "    output = proc_frame.copy()\n",
    "    # Draw zones and display zone counts.\n",
    "    for zname, zdata in zones.items():\n",
    "        polygon = zdata[\"polygon\"]\n",
    "        zone_color = zdata[\"color\"]\n",
    "        cv2.polylines(output, [polygon], isClosed=True, color=zone_color, thickness=3)\n",
    "        # Use midpoint of top-left and bottom-right of the zone rectangle.\n",
    "        pt1 = polygon[0]\n",
    "        pt3 = polygon[2]\n",
    "        cx = (pt1[0] + pt3[0]) // 2\n",
    "        cy = (pt1[1] + pt3[1]) // 2\n",
    "        count_text = f\"{zname}: {zone_counts[zname]}\"\n",
    "        text_size, _ = cv2.getTextSize(count_text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 2)\n",
    "        cv2.rectangle(output, (cx - 5, cy - text_size[1] - 10),\n",
    "                      (cx + text_size[0] + 5, cy), zone_color, thickness=-1)\n",
    "        cv2.putText(output, count_text, (cx, cy - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 2)\n",
    "    \n",
    "    # Draw detection bounding boxes.\n",
    "    for entry in annotated_bboxes:\n",
    "        x1, y1, x2, y2 = entry[\"bbox\"]\n",
    "        zone = entry[\"zone\"]\n",
    "        box_color = zones[zone][\"color\"] if zone is not None else (128, 128, 128)\n",
    "        cv2.rectangle(output, (x1, y1), (x2, y2), box_color, 2)\n",
    "        if label_display:\n",
    "            text_label = zone if zone is not None else \"None\"\n",
    "            cv2.putText(output, text_label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, box_color, 2)\n",
    "    \n",
    "    # Draw the global total count in the UPPER LEFT CORNER.\n",
    "    total_count = len(person_bboxes)\n",
    "    global_text = f\"Total: {total_count}\"\n",
    "    g_text_size, _ = cv2.getTextSize(global_text, cv2.FONT_HERSHEY_SIMPLEX, 2, 4)\n",
    "    cv2.rectangle(output, (10, 10), (10 + g_text_size[0] + 20, 10 + g_text_size[1] + 20), (0, 0, 0), thickness=-1)\n",
    "    cv2.putText(output, global_text, (20, 10 + g_text_size[1] + 5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# ====================================\n",
    "# 6. PROCESS THE SELECTED INPUT\n",
    "# ====================================\n",
    "if input_mode == \"image\":\n",
    "    # Process a single image.\n",
    "    output = process_frame(image)\n",
    "    cv2.imshow(\"Output\", output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    frame_count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Process only every Nth frame based on frame_skip.\n",
    "        if frame_count % frame_skip == 0:\n",
    "            output = process_frame(frame)\n",
    "            cv2.imshow(\"Output\", output)\n",
    "        else:\n",
    "            cv2.imshow(\"Output\", frame)\n",
    "        \n",
    "        frame_count += 1\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # Press ESC to exit.\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
